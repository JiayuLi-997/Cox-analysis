{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation\n",
    "import math, random\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Series_dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_name):\n",
    "        \n",
    "        np_dict = np.load(dataset_name,allow_pickle=True).item()\n",
    "        sort = np.argsort(np_dict[\"length\"])\n",
    "        self.items = np_dict[\"series\"].astype(np.float32)[sort]\n",
    "        self.targets = np_dict[\"churn\"].astype(int)[sort]\n",
    "        self.length = np_dict[\"length\"][sort]\n",
    "        self.input_size = np_dict[\"series\"][0].shape[1]\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return self.targets.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        return self.items[index],self.targets[index],self.length[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(\"../data/series_train.npy\",allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = train[\"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 30, 30, 30])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(train[\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 30, 30, 30])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length[np.argsort(train[\"length\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = train[\"series\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size, h_size,layers=1, dropout=0.5,output_dim=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "        input_size=input_size,\n",
    "        hidden_size=h_size, \n",
    "        num_layers=layers, \n",
    "        batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(h_size, output_dim)\n",
    "        \n",
    "    def forward(self, x, length):\n",
    "        \n",
    "        out, h_state = self.rnn(x)#, h_state)\n",
    "        out = self._gather_last_output(out,length)\n",
    "        \n",
    "        z = self.dropout(out)\n",
    "        y_pred = self.fc(z)\n",
    "        \n",
    "        return y_pred, h_state\n",
    "    \n",
    "    def _gather_last_output(self, output, seq_length):\n",
    "        seq_length = seq_length.long().detach().cpu().numpy() - 1\n",
    "        out = []\n",
    "        for batch_index, column_index in enumerate(seq_length):\n",
    "            out.append(output[batch_index, column_index])\n",
    "        return torch.stack(out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= 5\n",
    "h_size = 32\n",
    "layers=1\n",
    "dropout=0.5\n",
    "output_dim = 2\n",
    "l2_weight = 1e-5\n",
    "#gpu = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "max_epochs=20\n",
    "learning_rate = 0.001\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Series_dataset(\"../data/series_train.npy\")\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=batch_size,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Series_dataset(\"../data/series_val.npy\")\n",
    "val_data_loader = DataLoader(val_dataset,batch_size=batch_size,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, h_size,layers, dropout,output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    #rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    rounded_preds = np.array(preds.max(1)[1].data.tolist())\n",
    "    #print(preds.shape)\n",
    "    #print(rounded_preds.shape,y.shape)\n",
    "    correct = (rounded_preds == np.array(y.cpu()))#.float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 30, 5])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data_loader:\n",
    "    print(batch[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        x = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "        length = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions,h_state = model(x,length)#.squeeze(1)\n",
    "        loss = criterion(predictions, y)\n",
    "        acc = binary_accuracy(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator),epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            x = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "            length = batch[2].to(device)\n",
    "        \n",
    "            predictions,h_state = model(x,length)#.squeeze(1)\n",
    "            loss = criterion(predictions, y)\n",
    "            acc = binary_accuracy(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator),epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.679)| Train Acc: 58.03%\n",
      "\t Val. Loss: 0.648) |  Val. Acc: 63.33%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.632)| Train Acc: 65.77%\n",
      "\t Val. Loss: 0.640) |  Val. Acc: 63.16%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.631)| Train Acc: 65.68%\n",
      "\t Val. Loss: 0.605) |  Val. Acc: 70.86%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.619)| Train Acc: 67.67%\n",
      "\t Val. Loss: 0.607) |  Val. Acc: 69.66%\n",
      "Epoch: 05 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.630)| Train Acc: 66.13%\n",
      "\t Val. Loss: 0.627) |  Val. Acc: 70.73%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.632)| Train Acc: 64.75%\n",
      "\t Val. Loss: 0.600) |  Val. Acc: 71.26%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.624)| Train Acc: 65.84%\n",
      "\t Val. Loss: 0.605) |  Val. Acc: 69.95%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.625)| Train Acc: 66.06%\n",
      "\t Val. Loss: 0.612) |  Val. Acc: 69.45%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.626)| Train Acc: 65.82%\n",
      "\t Val. Loss: 0.609) |  Val. Acc: 70.95%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.632)| Train Acc: 65.04%\n",
      "\t Val. Loss: 0.602) |  Val. Acc: 71.02%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.620)| Train Acc: 67.03%\n",
      "\t Val. Loss: 0.595) |  Val. Acc: 70.34%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.617)| Train Acc: 67.44%\n",
      "\t Val. Loss: 0.590) |  Val. Acc: 69.93%\n",
      "Epoch: 13 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.623)| Train Acc: 66.65%\n",
      "\t Val. Loss: 0.606) |  Val. Acc: 70.48%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.628)| Train Acc: 65.86%\n",
      "\t Val. Loss: 0.604) |  Val. Acc: 69.81%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.619)| Train Acc: 67.52%\n",
      "\t Val. Loss: 0.599) |  Val. Acc: 70.35%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.623)| Train Acc: 66.96%\n",
      "\t Val. Loss: 0.615) |  Val. Acc: 69.66%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.627)| Train Acc: 66.73%\n",
      "\t Val. Loss: 0.596) |  Val. Acc: 69.76%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.627)| Train Acc: 66.26%\n",
      "\t Val. Loss: 0.621) |  Val. Acc: 70.85%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.641)| Train Acc: 63.60%\n",
      "\t Val. Loss: 0.634) |  Val. Acc: 71.11%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.638)| Train Acc: 63.97%\n",
      "\t Val. Loss: 0.605) |  Val. Acc: 70.45%\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss,train_acc = train(model, train_data_loader, optimizer, criterion)\n",
    "    valid_loss ,valid_acc = evaluate(model, val_data_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'RNN-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f})| Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}) |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
